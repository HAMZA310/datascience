{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost algorithm\n",
    "rewriting of the following code:https://hubpages.com/technology/Adaboost-in-Python<br>so happens that same example applies in http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/boosting.pdf.  Results tie with slides 17-20.<br>a helpful resource: http://mccormickml.com/2013/12/13/adaboost-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEZCAYAAABy91VnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh85qMy0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c1e9410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration 1 \n",
      "Dist [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "['wrong', 'wrong', 'wrong', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "prenorm'd [1.53, 1.53, 1.53, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65]\n",
      "dist_t [0.15, 0.15, 0.15, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07]\n",
      "  eps 1   0.3\n",
      "alpha 1   0.42\n",
      "    Z 1   0.92\n",
      "\n",
      "iteration 2 \n",
      "Dist [0.17, 0.17, 0.17, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.07]\n",
      "['correct', 'correct', 'correct', 'correct', 'correct', 'wrong', 'wrong', 'correct', 'wrong', 'correct']\n",
      "prenorm'd [0.52, 0.52, 0.52, 0.52, 0.52, 1.91, 1.91, 0.52, 1.91, 0.52]\n",
      "dist_t [0.09, 0.09, 0.09, 0.04, 0.04, 0.14, 0.14, 0.04, 0.14, 0.04]\n",
      "  eps 2   0.21\n",
      "alpha 2   0.65\n",
      "    Z 2   0.82\n",
      "\n",
      "iteration 3 \n",
      "Dist [0.11, 0.11, 0.11, 0.05, 0.05, 0.17, 0.17, 0.05, 0.17, 0.05]\n",
      "['correct', 'correct', 'correct', 'wrong', 'wrong', 'correct', 'correct', 'wrong', 'correct', 'correct']\n",
      "prenorm'd [0.4, 0.4, 0.4, 2.52, 2.52, 0.4, 0.4, 2.52, 0.4, 0.4]\n",
      "dist_t [0.04, 0.04, 0.04, 0.11, 0.11, 0.07, 0.07, 0.11, 0.07, 0.02]\n",
      "  eps 3   0.14\n",
      "alpha 3   0.92\n",
      "    Z 3   0.69\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def h(point, index, split_value, comparison_operator): \n",
    "    '''\n",
    "    Hypothesis function relating to decision-stump classifiers. \n",
    "    \n",
    "    Parameters\n",
    "      index               -  number associated with given feature\n",
    "      split_value         -  value used to split the training points into two groups\n",
    "      comparison_operator -  if string value equals 'less', less-than operator is used, \n",
    "                             otherwise greater than operator will be used\n",
    "   \n",
    "                     example                     computes \n",
    "          (point[index] < split_value)      :  True, or False\n",
    "      2 * (point[index] < split_value)      :  2, or 0 \n",
    "      2 * (point[index] > split_value) - 1  :  +1, or -1\n",
    "      \n",
    "    Returns               -  value of predicted label, +1 or -1\n",
    "    '''\n",
    "    if comparison_operator == 'less':\n",
    "        return 2 * (point[index] < split_value) - 1\n",
    "    else:\n",
    "        return 2 * (point[index] > split_value) - 1\n",
    "\n",
    "# load data\n",
    "data = np.array([\n",
    "[2.5,5.5, 1],  \n",
    "[3.5,6.5, 1], \n",
    "[4,  5.4, 1], \n",
    "[5,  5.5,-1], \n",
    "[1,  4,   1], \n",
    "[2,  4,  -1], \n",
    "[3.5,3.5,-1], \n",
    "[1,  2,   1],\n",
    "[2,  1,  -1], \n",
    "[5,  2,  -1]\n",
    "])\n",
    "\n",
    "N = len( data.tolist() )\n",
    "\n",
    "# sort points by class, and axis\n",
    "negv, negh, posv, posh = [], [], [], []\n",
    "for i in range(N):\n",
    "    if data[i][-1] == -1:\n",
    "        negv.append(data[:,0][i])\n",
    "        negh.append(data[:,1][i])\n",
    "    else:\n",
    "        posv.append(data[:,0][i])\n",
    "        posh.append(data[:,1][i])\n",
    "        \n",
    "# visualize\n",
    "plt.scatter(negv, negh, c='r', marker = 'o', s=50, label='-1 cls')\n",
    "plt.scatter(posv, posh, c='b', marker = 'o', s=50, label='+1 cls')\n",
    "xp = np.linspace(0, 5, 50)\n",
    "plt.xlabel(\"dim 1\")\n",
    "plt.ylabel(\"dim 2\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('visualization of data points')\n",
    "plt.show()\n",
    "\n",
    "# initialize Dist, alphas\n",
    "Dist = np.ones(N) / N \n",
    "alphas = []\n",
    "\n",
    "# decision stumps\n",
    "stumps = []\n",
    "stumps.append( {'index':0, 'value':1.5, 'oper':'less'   } ) \n",
    "stumps.append( {'index':0, 'value':4.5, 'oper':'less'   } )\n",
    "stumps.append( {'index':1, 'value':5  , 'oper':'greater'} )\n",
    "\n",
    "# main loop\n",
    "count = 1\n",
    "for s in stumps:\n",
    "    print '\\niteration', count, '\\nDist', [round(d,2) for d in Dist]\n",
    "\n",
    "    # retrive stump details from dictionary\n",
    "    ix, val, op = s['index'], s['value'], s['oper']\n",
    "    \n",
    "    # compute errors, as list of booleans\n",
    "    errors = np.array( [point[-1] != h(point, ix, val, op) for point in data] )\n",
    "    print ['correct' if err==False else 'wrong' for err in errors]\n",
    "\n",
    "    # compute epsillon\n",
    "    eps = sum( errors * Dist )\n",
    "    \n",
    "    # compute alpha_t\n",
    "    alpha_t = 0.5 * np.log( (1 - eps) / eps )\n",
    "   \n",
    "    # compute dist_t\n",
    "    dist_t = np.zeros(N)     \n",
    "    for i in range(N):\n",
    "        if errors[i] == 1: \n",
    "            dist_t[i] = Dist[i] * np.exp(alpha_t)\n",
    "        else: \n",
    "            dist_t[i] = Dist[i] * np.exp(-alpha_t)\n",
    "    pre_normalized = dist_t / Dist\n",
    "    print \"prenorm'd\", [round(w,2) for w in pre_normalized]\n",
    "    print 'dist_t', [round(d,2) for d in dist_t]\n",
    "\n",
    "    # update Distribution\n",
    "    Z_t = dist_t.sum()\n",
    "    Dist = dist_t / Z_t\n",
    "\n",
    "    print '  eps', count, ' ', round(eps, 2)\n",
    "    print 'alpha', count, ' ', round(alpha_t, 2)    \n",
    "    print '    Z', count, ' ', round(Z_t, 2)\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost algorithm (above, as object class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42364893019360172, 0.64964149206513044, 0.92291334524916546]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "def h(point, index, split_value, comparison_operator): \n",
    "    if comparison_operator == 'less':\n",
    "        return 2 * (point[index] < split_value) - 1\n",
    "    else:\n",
    "        return 2 * (point[index] > split_value) - 1\n",
    "        \n",
    "class AdaBoost:\n",
    " \n",
    "    def __init__(self, data, numLearners):\n",
    "        self.data = data                     # training data \n",
    "        self.N = len(self.data)              # number of training points\n",
    "        self.numLearners = numLearners       # number of decision-stumps \n",
    "        self.alphas = []                     # one real-value per decision-stump\n",
    "        self.stumps = []                     # one dictionary per decision-stump\n",
    "        self.Dist = np.ones(self.N)/self.N   # probability distribution\n",
    "        \n",
    "    def train(self):\n",
    "        comparisons = ['less','greater']\n",
    "        for i in range(self.numLearners):\n",
    "            min_eps = 999\n",
    "            # search for decision-stump with lowest epsillon,\n",
    "            # loop by operator, then by feature and row of training-data\n",
    "            for op in comparisons:\n",
    "                for ix in range( len(self.data[0]) - 1 ):\n",
    "                    for row in self.data:   \n",
    "                        errs = np.array( [pt[-1] != h(pt, ix, row[ix], op) for pt in self.data] )\n",
    "                        eps = sum( errs * self.Dist )\n",
    "                        if eps < min_eps:\n",
    "                            idx, val, oper, min_eps, errors = ix, row[ix], op, eps, errs               \n",
    "            # update probabilty distribution for next learner\n",
    "            dist = np.zeros(self.N)     \n",
    "            alpha = 0.5 * np.log( (1 - min_eps) / min_eps )\n",
    "            for i in range(self.N):\n",
    "                if errors[i] == 1: \n",
    "                    dist[i] = self.Dist[i] * np.exp(alpha)\n",
    "                else: \n",
    "                    dist[i] = self.Dist[i] * np.exp(-alpha) \n",
    "            self.Dist = dist / dist.sum()\n",
    "            # store classifier and alpha in model\n",
    "            self.stumps.append( {'index':idx, 'value':val, 'compare':oper} ) \n",
    "            self.alphas.append(alpha)\n",
    "                               \n",
    "# data is from AdaBoost example 1 (above)\n",
    "numLearners = 3  # number of decision-stumps, set by user\n",
    "m = AdaBoost(data, numLearners)\n",
    "m.train()\n",
    "m.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
