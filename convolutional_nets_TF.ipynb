{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cifar_data as cf\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(inp, W, S):\n",
    "    return tf.nn.conv2d(inp, W, strides=[1,S,S,1], padding='SAME')\n",
    "\n",
    "def conv_layer(inp, shape, stride):\n",
    "    W = weight_variable(shape)\n",
    "    b = bias_variable([shape[3]])\n",
    "    return tf.nn.relu(conv2d(inp, W, stride) + b)\n",
    "\n",
    "def pool_layer(inp, F, S):\n",
    "    return tf.nn.max_pool(inp, ksize=[1,F,F,1], strides=[1,S,S,1], padding='SAME')\n",
    "\n",
    "def full_layer(inp, dim):\n",
    "    in_size = int(inp.get_shape()[1])\n",
    "    W = weight_variable([in_size, dim])\n",
    "    b = bias_variable([dim])\n",
    "    return tf.matmul(inp, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST - Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| layer   | description    | length     | dimensions(shape)                   | hyperparameters (other than length)  | \n",
    "|:-------:|:--------------:|:----------:|:-----------------------------------:|:------------------------------------:|\n",
    "|         | Input          | n/a(batch) | 784                                 |                                      |\n",
    "| Layer 1 | Input(reshaped)| colorbar: 1| 28 x 28                             |                                      |\n",
    "| Layer 2 | Convolutional  | \\*32       | weights(5 x 5 x 1), output(28 x 28) | fieldsize=\\*5, stride=\\*1, pad=2     |\n",
    "| Layer 3 | Pooling        | 32         | output(14 x 14)                     | fieldsize=\\*2, stride=\\*2, pad=0     |\n",
    "| Layer 4 | Convolutional  | \\*64       | weights(5 x 5 x 32), output(14 x 14)| (same as layer 2)                    |\n",
    "| Layer 5 | Pooling        | 64         | output(7 x 7)                       | (same as layer 3)                    |\n",
    "| Layer 6 | Fully-Connected|            | input (3136)  output (\\*1024)       | with dropout, keep_prob=\\*0.5        | \n",
    "| Layer 7 | Output         |            | input (1024)  output(10)            | with dropout, keep_prob=\\*0.5        |\n",
    "|         |                |\\* value set by user                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "XShape: (55000, 784)\n",
      "yShape: (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "XShape = mnist.train.images.shape\n",
    "yShape = mnist.train.labels.shape\n",
    "print ('XShape:', XShape) \n",
    "print ('yShape:', yShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len2, len4 = 32, 64\n",
    "F_A, S_A = 5, 1\n",
    "F_B, S_B = 2, 2\n",
    "inp_shape = [None, XShape[1]]\n",
    "spatial_dim, dpth = int(np.sqrt(XShape[1])), 1\n",
    "reshape = [-1, spatial_dim, spatial_dim, dpth]\n",
    "shp2 = [F_A, F_A, dpth, len2]\n",
    "shp4 = [F_A, F_A, len2, len4]\n",
    "shp6out = 1024\n",
    "ydim = yShape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32) \n",
      " Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32) \n",
      " Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32) \n",
      " Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32) \n",
      " Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"Relu_2:0\", shape=(?, 1024), dtype=float32) \n",
      " Tensor(\"add_3:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inp = tf.placeholder(tf.float32, inp_shape)\n",
    "layer1 = tf.reshape(inp, reshape)\n",
    "layer2 = conv_layer(layer1, shp2, S_A)\n",
    "layer3 = pool_layer(layer2, F_B, S_B)\n",
    "layer4 = conv_layer(layer3, shp4, S_A)\n",
    "layer5 = pool_layer(layer4, F_B, S_B)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "shp6in = [ -1, int(layer5.shape[1]) * int(layer5.shape[2]) * int(layer5.shape[3]) ]\n",
    "flattened = tf.reshape(layer5, shp6in)\n",
    "droppedA = tf.nn.dropout(flattened, keep_prob=keep_prob)\n",
    "layer6 = tf.nn.relu(full_layer(droppedA, shp6out))\n",
    "\n",
    "droppedB = tf.nn.dropout(layer6, keep_prob=keep_prob) \n",
    "layer7 = full_layer(droppedB, ydim)\n",
    "\n",
    "print (inp, '\\n', layer2, '\\n', layer3, '\\n', layer4, '\\n', layer5)\n",
    "print (layer6, '\\n', layer7)\n",
    "\n",
    "yShape = [None, ydim]\n",
    "lbls = tf.placeholder(tf.float32, shape=yShape)\n",
    "results = tf.nn.softmax_cross_entropy_with_logits(logits=layer7, labels=lbls)\n",
    "cross_entropy = tf.reduce_mean(results)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(layer7, 1), tf.argmax(lbls, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.05999999865889549\n",
      "step 100, training accuracy 0.6200000047683716\n",
      "step 200, training accuracy 0.9200000166893005\n",
      "step 300, training accuracy 0.8799999952316284\n",
      "step 400, training accuracy 0.8600000143051147\n",
      "step 500, training accuracy 0.8999999761581421\n",
      "step 600, training accuracy 0.8600000143051147\n",
      "step 700, training accuracy 0.9800000190734863\n",
      "step 800, training accuracy 0.8999999761581421\n",
      "step 900, training accuracy 0.8799999952316284\n",
      "test accuracy: 0.947100043296814\n"
     ]
    }
   ],
   "source": [
    "batchSize = 50\n",
    "numSteps = 901  # recommended 5000\n",
    "nTest = 1000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(numSteps):\n",
    "        batch = mnist.train.next_batch(batchSize)\n",
    "        \n",
    "        # display accuracy on in-sample images (every 100 steps)\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={inp: batch[0], lbls: batch[1],\n",
    "                                                           keep_prob: 1.0})\n",
    "            print(\"step {}, training accuracy {}\".format(i, train_accuracy))\n",
    "            \n",
    "        # train next batch\n",
    "        sess.run(train_step, feed_dict={inp: batch[0], lbls: batch[1], keep_prob: 0.5})\n",
    "        \n",
    "    # test accuracy on out-of-sample images\n",
    "    X = mnist.test.images.reshape(ydim, nTest, XShape[1])\n",
    "    Y = mnist.test.labels.reshape(ydim, nTest, ydim)\n",
    "    acc = np.mean([sess.run(accuracy, feed_dict={inp: X[i], lbls: Y[i], keep_prob: 1.0}) \n",
    "                   for i in range(ydim)]) \n",
    "    \n",
    "print(\"test accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR - Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| layer   | description    | length     | dimensions(shape)                   | hyperparameters (other than length)  | \n",
    "|:-------:|:--------------:|:----------:|:-----------------------------------:|:------------------------------------:|\n",
    "| Layer 1 | Input          | colorbar: 3| 32 x 32 x 3                         |                                      |\n",
    "| Layer 2 | Convolutional  | \\*32       | weights(5 x 5 x 3), output(32 x 32) | fieldsize=\\*5, stride=\\*1, pad=2     |\n",
    "| Layer 3 | Pooling        | 32         | output(16 x 16)                     | fieldsize=\\*2, stride=\\*2, pad=0     |\n",
    "| Layer 4 | Convolutional  | \\*64       | weights(5 x 5 x 32), output(16 x 16)| (same as layer 2)                    |\n",
    "| Layer 5 | Pooling        | 64         | output(8 x 8)                       | (same as layer 3)                    |\n",
    "| Layer 6 | Convolutional  | \\*128      | weights(5 x 5 x 64), output(8 x 8)  | (same as layer 2)                    |\n",
    "| Layer 7 | Pooling        | 128        | output(4 x 4)                       | (same as layer 3)                    |\n",
    "| Layer 8 | Fully-Connected|            | input (2048)  output (\\*512)        | with dropout, keep_prob=\\*0.5        | \n",
    "| Layer 9 | Output         |            | input (512)  output(10)             | with dropout, keep_prob=\\*0.5        |\n",
    "|         |                |\\* value set by user                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XShape: (50000, 32, 32, 3)\n",
      "yShape: (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "import cifar_data as cf\n",
    "d = cf.CifarDataManager()\n",
    "images = d.train.images\n",
    "XShape = d.train.images.shape\n",
    "yShape = d.train.labels.shape\n",
    "print ('XShape:', XShape)\n",
    "print ('yShape:', yShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_A, S_A = 5, 1\n",
    "F_B, S_B = 2, 2\n",
    "len2, len4, len6  = 32, 64, 128\n",
    "shp1 = [None, XShape[1], XShape[2], XShape[3]]\n",
    "shp2 = [F_A, F_A, XShape[3], len2]\n",
    "shp4 = [F_A, F_A, len2, len4]\n",
    "shp6 = [F_A, F_A, len4, len6]\n",
    "shp8out = 512\n",
    "ydim = yShape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_3:0\", shape=(?, 32, 32, 3), dtype=float32) \n",
      " Tensor(\"Relu_3:0\", shape=(?, 32, 32, 32), dtype=float32) \n",
      " Tensor(\"MaxPool_2:0\", shape=(?, 16, 16, 32), dtype=float32) \n",
      " Tensor(\"Relu_4:0\", shape=(?, 16, 16, 64), dtype=float32) \n",
      " Tensor(\"MaxPool_3:0\", shape=(?, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"Relu_5:0\", shape=(?, 8, 8, 128), dtype=float32) \n",
      " Tensor(\"MaxPool_4:0\", shape=(?, 4, 4, 128), dtype=float32) \n",
      " Tensor(\"Relu_6:0\", shape=(?, 512), dtype=float32) \n",
      " Tensor(\"add_8:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inp = tf.placeholder(tf.float32, shape=shp1)\n",
    "layer2 = conv_layer(inp, shp2, S_A)\n",
    "layer3 = pool_layer(layer2, F_B, S_B)\n",
    "layer4 = conv_layer(layer3, shp4, S_A)\n",
    "layer5 = pool_layer(layer4, F_B, S_B)\n",
    "layer6 = conv_layer(layer5, shp6, S_A)\n",
    "layer7 = pool_layer(layer6, F_B, S_B)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "shp8in = [ -1, int(layer7.shape[1]) * int(layer7.shape[2]) * int(layer7.shape[3]) ]\n",
    "flattened = tf.reshape(layer7, shp8in)\n",
    "droppedA = tf.nn.dropout(flattened, keep_prob=keep_prob)\n",
    "layer8 = tf.nn.relu(full_layer(droppedA, shp8out))\n",
    "\n",
    "droppedB = tf.nn.dropout(layer8, keep_prob=keep_prob) \n",
    "layer9 = full_layer(droppedB, ydim)\n",
    "\n",
    "print (inp, '\\n', layer2, '\\n', layer3, '\\n', layer4, '\\n', layer5)\n",
    "print (layer6, '\\n', layer7, '\\n', layer8, '\\n', layer9)\n",
    "\n",
    "yShape = [None, ydim]\n",
    "lbls = tf.placeholder(tf.float32, shape=yShape)\n",
    "results = tf.nn.softmax_cross_entropy_with_logits(logits=layer9, labels=lbls)\n",
    "cross_entropy = tf.reduce_mean(results)\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(layer9, 1), tf.argmax(lbls, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.019999999552965164\n",
      "step 100, training accuracy 0.2800000011920929\n",
      "step 200, training accuracy 0.3400000035762787\n",
      "step 300, training accuracy 0.30000001192092896\n",
      "step 400, training accuracy 0.4000000059604645\n",
      "step 500, training accuracy 0.5799999833106995\n",
      "test accuracy: 0.4301000237464905\n"
     ]
    }
   ],
   "source": [
    "batchSize = 50\n",
    "numSteps = 501  # recommended 500000\n",
    "nTest = 1000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(numSteps):\n",
    "        batch = d.train.next_batch(batchSize)\n",
    "        \n",
    "        # display accuracy on in-sample images (every 100 steps)\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={inp: batch[0], lbls: batch[1],\n",
    "                                                           keep_prob: 1.0})\n",
    "            print(\"step {}, training accuracy {}\".format(i, train_accuracy))\n",
    "            \n",
    "        # train next batch\n",
    "        sess.run(train_step, feed_dict={inp: batch[0], lbls: batch[1], keep_prob: 0.5})\n",
    "        \n",
    "    # test accuracy on out-of-sample images\n",
    "    X = d.test.images.reshape(ydim, nTest, XShape[1], XShape[2], XShape[3])\n",
    "    Y = d.test.labels.reshape(ydim, nTest, ydim)\n",
    "    acc = np.mean([sess.run(accuracy, feed_dict={inp: X[i], lbls: Y[i], keep_prob: 1.0}) \n",
    "                   for i in range(ydim)]) \n",
    "    \n",
    "print(\"test accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### CIFAR - Model II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: length parameters match with example from text (not github site, https://github.com/Hezi-Resheff/Oreilly-Learning-TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "| layer   | description    | length     | dimensions(shape)                   | hyperparameters (other than length)  | \n",
    "|:-------:|:--------------:|:----------:|:-----------------------------------:|:------------------------------------:|\n",
    "| Layer 1 | Input          | colorbar: 3| 32 x 32 x 3                         |                                      |\n",
    "| Layer 2a| Convolutional  | \\*30       | weights(3 x 3 x 3), output(32 x 32) | fieldsize=\\*3, stride=\\*1, pad=1     |\n",
    "| Layer 2b| Convolutional  | \\*30       | weights(3 x 3 x 30), output(32 x 32)| same as 2a                           |\n",
    "| Layer 2c| Convolutional  | \\*30       | weights(3 x 3 x 30), output(32 x 32)| same as 2a                           |\n",
    "| Layer 2d| Pooling        | 30         | output(16 x 16)                     | fieldsize=\\*2, stride=\\*2, pad=0     |\n",
    "| Layer 3a| Convolutional  | \\*50       | weights(3 x 3 x 30), output(16 x 16)| same as 2a                           |\n",
    "| Layer 3b| Convolutional  | \\*50       | weights(3 x 3 x 50), output(16 x 16)| same as 2a                           |\n",
    "| Layer 3c| Convolutional  | \\*50       | weights(3 x 3 x 50), output(16 x 16)| same as 2a                           |\n",
    "| Layer 3d| Pooling        | 50         | output(8 x 8)                       | same as 2d                           |\n",
    "| Layer 4a| Convolutional  | \\*80       | weights(3 x 3 x 50), output(8 x 8)  | same as 2a                           |\n",
    "| Layer 4b| Convolutional  | \\*80       | weights(3 x 3 x 80), output(8 x 8)  | same as 2a                           |\n",
    "| Layer 4c| Convolutional  | \\*80       | weights(3 x 3 x 80), output(8 x 8)  | same as 2a                           |\n",
    "| Layer 4d| Pooling        | 80         | output(1 x 1)                       | fieldsize=\\*8, stride=\\*8, pad=0     |\n",
    "| Layer 5 | Fully-Connected|     \t    | input (80) output (\\*500)         | with dropout, keep_prob=\\*0.5        |\n",
    "| Layer 6 | Output         |            | input (500)  output(10)             | with dropout, keep_prob=\\*0.5        |\n",
    "|         |                |\\* value set by user                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XShape: (50000, 32, 32, 3)\n",
      "yShape: (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "d = cf.CifarDataManager()\n",
    "images = d.train.images\n",
    "XShape = d.train.images.shape\n",
    "yShape = d.train.labels.shape\n",
    "print ('XShape:', XShape)\n",
    "print ('yShape:', yShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Network Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_A, S_A = 3, 1\n",
    "F_B, S_B = 2, 2\n",
    "F_C, S_C = 8, 8\n",
    "len2, len3, len4 = 30, 50, 80\n",
    "shp1 = [None, XShape[1], XShape[2], XShape[3]]\n",
    "shp2a = [F_A, F_A, XShape[3], len2]\n",
    "shp2b = [F_A, F_A, len2, len2]\n",
    "shp2c = [F_A, F_A, len2, len2]\n",
    "shp3a = [F_A, F_A, len2, len3]\n",
    "shp3b = [F_A, F_A, len3, len3]\n",
    "shp3c = [F_A, F_A, len3, len3]\n",
    "shp4a = [F_A, F_A, len3, len4]\n",
    "shp4b = [F_A, F_A, len4, len4]\n",
    "shp4c = [F_A, F_A, len4, len4]\n",
    "shp5in = [-1, len4]\n",
    "shp5out = 500\n",
    "ydim = yShape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_6:0\", shape=(?, 32, 32, 3), dtype=float32) \n",
      " Tensor(\"Relu_7:0\", shape=(?, 32, 32, 30), dtype=float32) \n",
      " Tensor(\"Relu_8:0\", shape=(?, 32, 32, 30), dtype=float32) \n",
      " Tensor(\"Relu_9:0\", shape=(?, 32, 32, 30), dtype=float32) \n",
      " Tensor(\"MaxPool_5:0\", shape=(?, 16, 16, 30), dtype=float32)\n",
      "Tensor(\"Relu_10:0\", shape=(?, 16, 16, 50), dtype=float32) \n",
      " Tensor(\"Relu_11:0\", shape=(?, 16, 16, 50), dtype=float32) \n",
      " Tensor(\"Relu_12:0\", shape=(?, 16, 16, 50), dtype=float32) \n",
      " Tensor(\"MaxPool_6:0\", shape=(?, 8, 8, 50), dtype=float32) \n",
      " Tensor(\"Relu_13:0\", shape=(?, 8, 8, 80), dtype=float32)\n",
      "Tensor(\"Relu_14:0\", shape=(?, 8, 8, 80), dtype=float32) \n",
      " Tensor(\"Relu_15:0\", shape=(?, 8, 8, 80), dtype=float32) \n",
      " Tensor(\"MaxPool_7:0\", shape=(?, 1, 1, 80), dtype=float32) \n",
      " Tensor(\"Relu_16:0\", shape=(?, 500), dtype=float32) \n",
      " Tensor(\"add_19:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inp = tf.placeholder(tf.float32, shape=shp1)\n",
    "layer2a = conv_layer(inp, shp2a, S_A)\n",
    "layer2b = conv_layer(layer2a, shp2b, S_A)\n",
    "layer2c = conv_layer(layer2b, shp2c, S_A)\n",
    "layer2d = pool_layer(layer2c, F_B, S_B)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "droppedA = tf.nn.dropout(layer2d, keep_prob=keep_prob) \n",
    "layer3a = conv_layer(droppedA, shp3a, S_A)\n",
    "layer3b = conv_layer(layer3a, shp3b, S_A)\n",
    "layer3c = conv_layer(layer3b, shp3c, S_A)\n",
    "layer3d = pool_layer(layer3c, F_B, S_B)\n",
    "\n",
    "droppedB = tf.nn.dropout(layer3d, keep_prob=keep_prob) \n",
    "layer4a = conv_layer(droppedB, shp4a, S_A)\n",
    "layer4b = conv_layer(layer4a, shp4b, S_A)\n",
    "layer4c = conv_layer(layer4b, shp4c, S_A)\n",
    "layer4d = pool_layer(layer4c, F_C, S_C)\n",
    "\n",
    "flattened = tf.reshape(layer4d, shp5in)\n",
    "droppedC = tf.nn.dropout(flattened, keep_prob=keep_prob)\n",
    "layer5 = tf.nn.relu(full_layer(droppedC, shp5out))\n",
    "\n",
    "droppedD = tf.nn.dropout(layer5, keep_prob=keep_prob)\n",
    "layer6 =  full_layer(droppedD, ydim)\n",
    "\n",
    "print (inp, '\\n', layer2a, '\\n', layer2b, '\\n', layer2c, '\\n', layer2d)\n",
    "print (layer3a, '\\n', layer3b, '\\n', layer3c, '\\n', layer3d, '\\n', layer4a)\n",
    "print (layer4b, '\\n', layer4c, '\\n', layer4d, '\\n', layer5, '\\n', layer6)\n",
    "\n",
    "yShape = [None, ydim]\n",
    "lbls = tf.placeholder(tf.float32, shape=yShape)\n",
    "results = tf.nn.softmax_cross_entropy_with_logits(logits=layer6, labels=lbls)\n",
    "cross_entropy = tf.reduce_mean(results)\n",
    "train_step = tf.train.AdamOptimizer(5e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(layer6, 1), tf.argmax(lbls, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.03999999910593033\n",
      "step 100, training accuracy 0.11999999731779099\n",
      "step 200, training accuracy 0.019999999552965164\n",
      "step 300, training accuracy 0.14000000059604645\n",
      "step 400, training accuracy 0.10000000149011612\n",
      "step 500, training accuracy 0.10000000149011612\n",
      "test accuracy: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "batchSize = 50\n",
    "numSteps = 501  # recommended 500000\n",
    "nTest = 1000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(numSteps):\n",
    "        batch = d.train.next_batch(batchSize)\n",
    "        \n",
    "        # display accuracy on in-sample images (every 100 steps)\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={inp: batch[0], lbls: batch[1],\n",
    "                                                           keep_prob: 1.0})\n",
    "            print(\"step {}, training accuracy {}\".format(i, train_accuracy))\n",
    "            \n",
    "        # train next batch\n",
    "        sess.run(train_step, feed_dict={inp: batch[0], lbls: batch[1], keep_prob: 0.5})\n",
    "        \n",
    "    # test accuracy on out-of-sample images\n",
    "    X = d.test.images.reshape(ydim, nTest, XShape[1], XShape[2], XShape[3])\n",
    "    Y = d.test.labels.reshape(ydim, nTest, ydim)\n",
    "    acc = np.mean([sess.run(accuracy, feed_dict={inp: X[i], lbls: Y[i], keep_prob: 1.0}) \n",
    "                   for i in range(ydim)]) \n",
    "    \n",
    "print(\"test accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
